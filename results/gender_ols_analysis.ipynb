{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import seaborn as sb\n",
    "import pingouin as pg\n",
    "import random\n",
    "import os\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (6, 6),\n",
    "         'axes.labelsize': 20,\n",
    "         'axes.titlesize':16,\n",
    "         'axes.labelcolor':\"#000000\",\n",
    "         'xtick.labelsize':20,\n",
    "         'ytick.labelsize':16,\n",
    "         'font.weight':\"normal\",\n",
    "         'xtick.color':\"#000000\",\n",
    "         'ytick.color':\"#000000\",\n",
    "         'axes.labelweight':'normal'}\n",
    "pylab.rcParams.update(params)\n",
    "%matplotlib inline\n",
    "\n",
    "data_src = './cloud_results/'\n",
    "save_dir = f'./statistics/new/'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Pretrained</th>\n",
       "      <th>Attack</th>\n",
       "      <th>misclassification_rate</th>\n",
       "      <th>female2male_rate</th>\n",
       "      <th>male2female_rate</th>\n",
       "      <th>total</th>\n",
       "      <th>nr_female</th>\n",
       "      <th>nr_male</th>\n",
       "      <th>mis_ratio</th>\n",
       "      <th>female2male_rate_100</th>\n",
       "      <th>male2female_rate_100</th>\n",
       "      <th>is_Pretrained</th>\n",
       "      <th>local_success_rate</th>\n",
       "      <th>cloud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inception</td>\n",
       "      <td>raw</td>\n",
       "      <td>V3</td>\n",
       "      <td>True</td>\n",
       "      <td>BLB</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>200</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>aliyun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inception</td>\n",
       "      <td>raw</td>\n",
       "      <td>V3</td>\n",
       "      <td>True</td>\n",
       "      <td>CW2</td>\n",
       "      <td>0.050251</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>199</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "      <td>aliyun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inception</td>\n",
       "      <td>raw</td>\n",
       "      <td>V3</td>\n",
       "      <td>True</td>\n",
       "      <td>DEEPFOOL</td>\n",
       "      <td>0.040698</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.057471</td>\n",
       "      <td>172</td>\n",
       "      <td>85</td>\n",
       "      <td>87</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.860</td>\n",
       "      <td>aliyun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inception</td>\n",
       "      <td>raw</td>\n",
       "      <td>V3</td>\n",
       "      <td>True</td>\n",
       "      <td>FGSM</td>\n",
       "      <td>0.102151</td>\n",
       "      <td>0.118280</td>\n",
       "      <td>0.086022</td>\n",
       "      <td>186</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930</td>\n",
       "      <td>aliyun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inception</td>\n",
       "      <td>raw</td>\n",
       "      <td>V3</td>\n",
       "      <td>True</td>\n",
       "      <td>LLC</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>106</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530</td>\n",
       "      <td>aliyun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Architecture Data_type Depth  Pretrained    Attack  misclassification_rate  \\\n",
       "0    inception       raw    V3        True       BLB                0.050000   \n",
       "1    inception       raw    V3        True       CW2                0.050251   \n",
       "2    inception       raw    V3        True  DEEPFOOL                0.040698   \n",
       "3    inception       raw    V3        True      FGSM                0.102151   \n",
       "4    inception       raw    V3        True       LLC                0.056604   \n",
       "\n",
       "   female2male_rate  male2female_rate  total  nr_female  nr_male  mis_ratio  \\\n",
       "0          0.050000          0.050000    200        100      100      0.050   \n",
       "1          0.050000          0.050505    199        100       99      0.050   \n",
       "2          0.023529          0.057471    172         85       87      0.035   \n",
       "3          0.118280          0.086022    186         93       93      0.095   \n",
       "4          0.076923          0.037037    106         52       54      0.030   \n",
       "\n",
       "   female2male_rate_100  male2female_rate_100  is_Pretrained  \\\n",
       "0                  0.05                  0.05              1   \n",
       "1                  0.05                  0.05              1   \n",
       "2                  0.02                  0.05              1   \n",
       "3                  0.11                  0.08              1   \n",
       "4                  0.04                  0.02              1   \n",
       "\n",
       "   local_success_rate   cloud  \n",
       "0               1.000  aliyun  \n",
       "1               0.995  aliyun  \n",
       "2               0.860  aliyun  \n",
       "3               0.930  aliyun  \n",
       "4               0.530  aliyun  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Variable2Vitual(df, attribute, values=None):\n",
    "    # convert a multi-value attribute column to multiple virtual variables\n",
    "    if values is None:\n",
    "        values = set(df[attribute])\n",
    "    for v in values:\n",
    "        df[f'is_{v}'] = (df[attribute]==v).astype(int)\n",
    "    return df\n",
    "\n",
    "def read_cloud(csv_path, cloud_name):\n",
    "    # preprocess the csv data\n",
    "    data = pd.read_csv(csv_path)\n",
    "    data['Attack'] = data['Attack'].str.upper()\n",
    "    data['Attack'][data['Attack'] == 'BL-BFGS'] = 'BLB'\n",
    "    data['is_Pretrained'] = data['Pretrained'].astype(int)\n",
    "    data['local_success_rate'] = data['total']/200\n",
    "    data['cloud'] = cloud_name\n",
    "    return data\n",
    "\n",
    "def export_ols(ols_result, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(ols_result.summary().as_csv())\n",
    "\n",
    "dataset = 'AdienceGenderG'\n",
    "df_list = []\n",
    "for cloud in ['aliyun', 'baidu', 'aws']:\n",
    "    csv_path = data_src+f'{cloud}_{dataset}.csv'\n",
    "    df = read_cloud(csv_path, cloud)\n",
    "    df_list.append(df)\n",
    "data = pd.concat(df_list, axis=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>female2male_rate</th>\n",
       "      <th>male2female_rate</th>\n",
       "      <th>nr_female</th>\n",
       "      <th>nr_male</th>\n",
       "      <th>female2male_rate_100</th>\n",
       "      <th>male2female_rate_100</th>\n",
       "      <th>is_Pretrained</th>\n",
       "      <th>is_vgg</th>\n",
       "      <th>is_inception</th>\n",
       "      <th>is_resnet</th>\n",
       "      <th>...</th>\n",
       "      <th>is_UAP</th>\n",
       "      <th>is_STEP_LLC</th>\n",
       "      <th>is_RFGSM</th>\n",
       "      <th>is_LLC</th>\n",
       "      <th>is_aws</th>\n",
       "      <th>is_aliyun</th>\n",
       "      <th>is_baidu</th>\n",
       "      <th>is_18</th>\n",
       "      <th>is_34</th>\n",
       "      <th>is_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.057471</td>\n",
       "      <td>85</td>\n",
       "      <td>87</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.118280</td>\n",
       "      <td>0.086022</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   female2male_rate  male2female_rate  nr_female  nr_male  \\\n",
       "0          0.050000          0.050000        100      100   \n",
       "1          0.050000          0.050505        100       99   \n",
       "2          0.023529          0.057471         85       87   \n",
       "3          0.118280          0.086022         93       93   \n",
       "4          0.076923          0.037037         52       54   \n",
       "\n",
       "   female2male_rate_100  male2female_rate_100  is_Pretrained  is_vgg  \\\n",
       "0                  0.05                  0.05              1       0   \n",
       "1                  0.05                  0.05              1       0   \n",
       "2                  0.02                  0.05              1       0   \n",
       "3                  0.11                  0.08              1       0   \n",
       "4                  0.04                  0.02              1       0   \n",
       "\n",
       "   is_inception  is_resnet  ...  is_UAP  is_STEP_LLC  is_RFGSM  is_LLC  \\\n",
       "0             1          0  ...       0            0         0       0   \n",
       "1             1          0  ...       0            0         0       0   \n",
       "2             1          0  ...       0            0         0       0   \n",
       "3             1          0  ...       0            0         0       0   \n",
       "4             1          0  ...       0            0         0       1   \n",
       "\n",
       "   is_aws  is_aliyun  is_baidu  is_18  is_34  is_50  \n",
       "0       0          1         0      0      0      0  \n",
       "1       0          1         0      0      0      0  \n",
       "2       0          1         0      0      0      0  \n",
       "3       0          1         0      0      0      0  \n",
       "4       0          1         0      0      0      0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reformalize data\n",
    "for attr in ['Architecture', 'Data_type', 'Attack', 'cloud']:\n",
    "    data = Variable2Vitual(data, attr)\n",
    "data = Variable2Vitual(data, 'Depth', ['18', '34', '50'])\n",
    "# remove unnecessary columns\n",
    "df = data.drop(['Architecture', 'Data_type', 'Attack', 'Depth', 'total', 'Pretrained', 'mis_ratio', 'cloud', 'local_success_rate', 'misclassification_rate'], axis=1)\n",
    "res_df = df[df['is_resnet']==1].copy(deep=True).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['female2male_rate', 'male2female_rate', 'nr_female', 'nr_male',\n",
       "       'female2male_rate_100', 'male2female_rate_100', 'is_Pretrained',\n",
       "       'is_vgg', 'is_inception', 'is_resnet', 'is_augmented', 'is_raw',\n",
       "       'is_adversarial', 'is_FGSM', 'is_DEEPFOOL', 'is_BLB', 'is_CW2',\n",
       "       'is_PGD', 'is_UAP', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC', 'is_aws',\n",
       "       'is_aliyun', 'is_baidu', 'is_18', 'is_34', 'is_50'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize all the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The large OLS table and statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two methods for comparing coefficients. We use Wald's R test \n",
    "\n",
    "# def Generate_Compare_Formula(original_formula, compare_v1, compare_v2):\n",
    "#     # helper func for generating formula for compare two factors\n",
    "#     # It removes v1 and v2 from the formula, but adds v1+v2 and v1-v2.\n",
    "#     # Assume the regression coefficient of v1+v2 is x and the coefficient of v1-v2 is y.\n",
    "#     # If y>0 significantly, then the regression model x(v1+v2)+y(v1-v2) = (x+y)v1 + (x-y)v2, and thus the coefficient of v2 is less than v1 since x-y < x+y. The p-value of the test y<=0 is thus a valid p-value for the latter.\n",
    "#     original_formula = original_formula + f'-{compare_v1}-{compare_v2}'\n",
    "#     original_formula += f'+I({compare_v1}+{compare_v2})+I({compare_v2}-{compare_v1})'\n",
    "#     return original_formula\n",
    "\n",
    "def Test_Wald_R(ols_result, R_coef:list, R_var_name:list, return_result=False):\n",
    "    # Test H0: R * coef = 0.\n",
    "    # e.g. For R_coef = [1,-1], coef = [is_aliyun, is_baidu], this tests H0: is_aliyun - is_baidu = 0, which is equivalent to test H0: is_aliyun = is_baidu.\n",
    "    # this is used to compare the coefficients of variables.\n",
    "    assert len(R_coef) == len(R_var_name), 'One to one map should be given.'\n",
    "    params = ols_result.params\n",
    "    idx_map = dict([(list(params.index)[i], i) for i in range(len(list(params.index)))])\n",
    "    R = np.zeros(len(params))\n",
    "    for r, var in zip(R_coef, R_var_name):\n",
    "        R[idx_map[var]] = r\n",
    "    test = ols_result.wald_test(R)\n",
    "    print(test.summary())\n",
    "    if return_result:\n",
    "        return test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression A\n",
    "\n",
    "dependent variable: female2male rate\n",
    "\n",
    "explain variables: platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female2male_rate ~ 0+is_aws+is_baidu+is_aliyun\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>female2male_rate</td> <th>  R-squared:         </th> <td>   0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   42.77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>7.90e-18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:09:14</td>     <th>  Log-Likelihood:    </th> <td>  723.62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   486</td>      <th>  AIC:               </th> <td>  -1441.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   483</td>      <th>  BIC:               </th> <td>  -1429.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aws</th>    <td>    0.0278</td> <td>    0.004</td> <td>    6.461</td> <td> 0.000</td> <td>    0.019</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_baidu</th>  <td>    0.0687</td> <td>    0.004</td> <td>   15.957</td> <td> 0.000</td> <td>    0.060</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aliyun</th> <td>    0.0817</td> <td>    0.004</td> <td>   19.000</td> <td> 0.000</td> <td>    0.073</td> <td>    0.090</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>184.958</td> <th>  Durbin-Watson:     </th> <td>   1.822</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 622.320</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.782</td>  <th>  Prob(JB):          </th> <td>7.33e-136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.246</td>  <th>  Cond. No.          </th> <td>    1.00</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       female2male_rate   R-squared:                       0.150\n",
       "Model:                            OLS   Adj. R-squared:                  0.147\n",
       "Method:                 Least Squares   F-statistic:                     42.77\n",
       "Date:                Tue, 15 Mar 2022   Prob (F-statistic):           7.90e-18\n",
       "Time:                        21:09:14   Log-Likelihood:                 723.62\n",
       "No. Observations:                 486   AIC:                            -1441.\n",
       "Df Residuals:                     483   BIC:                            -1429.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "is_aws         0.0278      0.004      6.461      0.000       0.019       0.036\n",
       "is_baidu       0.0687      0.004     15.957      0.000       0.060       0.077\n",
       "is_aliyun      0.0817      0.004     19.000      0.000       0.073       0.090\n",
       "==============================================================================\n",
       "Omnibus:                      184.958   Durbin-Watson:                   1.822\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              622.320\n",
       "Skew:                           1.782   Prob(JB):                    7.33e-136\n",
       "Kurtosis:                       7.246   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_exp = ['is_google', 'is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC', 'is_34', 'is_50']\n",
    "\n",
    "# baseline setting: raw + UAP + 18\n",
    "exp_vs = ['is_aws', 'is_baidu', 'is_aliyun']\n",
    "\n",
    "dp_variable = 'female2male_rate'\n",
    "\n",
    "formula = '{} ~ 0+{}'.format(dp_variable, '+'.join(exp_vs)) # exclude the intercept\n",
    "# formula = Generate_Compare_Formula(formula, 'is_FGSM', 'is_DEEPFOOL')\n",
    "\n",
    "# add cross terms to formula\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_augmented',]])\n",
    "# formula += '+' + '+'.join([f'I({attr1}*{attr2})' for attr1 in ['is_Pretrained', 'is_adversarial', 'is_augmented', ] for attr2 in ['is_34', 'is_50']])\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC',]])\n",
    "\n",
    "print(formula)\n",
    "model = ols(formula, data=res_df)\n",
    "results = model.fit()\n",
    "# export_ols(results, './ols_result/imagenet/joint_ols_match.csv')\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<F test: F=array([[45.08108669]]), p=5.321236765348104e-11, df_denom=483, df_num=1>\n",
      "<F test: F=array([[4.6303017]]), p=0.03190705108481524, df_denom=483, df_num=1>\n"
     ]
    }
   ],
   "source": [
    "# Test: AWS < Baidu < Aliyun\n",
    "\n",
    "Test_Wald_R(results, [1,-1], ['is_aws', 'is_baidu'])\n",
    "Test_Wald_R(results, [1,-1], ['is_baidu', 'is_aliyun'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression B\n",
    "\n",
    "dependent variable: female2male rate\n",
    "\n",
    "explain variables: platform + pretraining + dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female2male_rate ~ 0+is_aws+is_baidu+is_aliyun+is_Pretrained+is_adversarial+is_augmented\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>female2male_rate</td> <th>  R-squared:         </th> <td>   0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   26.76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>6.96e-24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:09:14</td>     <th>  Log-Likelihood:    </th> <td>  743.74</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   486</td>      <th>  AIC:               </th> <td>  -1475.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   480</td>      <th>  BIC:               </th> <td>  -1450.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aws</th>         <td>    0.0231</td> <td>    0.006</td> <td>    3.953</td> <td> 0.000</td> <td>    0.012</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_baidu</th>       <td>    0.0640</td> <td>    0.006</td> <td>   10.929</td> <td> 0.000</td> <td>    0.052</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aliyun</th>      <td>    0.0771</td> <td>    0.006</td> <td>   13.165</td> <td> 0.000</td> <td>    0.066</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_Pretrained</th>  <td>    0.0186</td> <td>    0.005</td> <td>    3.896</td> <td> 0.000</td> <td>    0.009</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_adversarial</th> <td>   -0.0214</td> <td>    0.006</td> <td>   -3.661</td> <td> 0.000</td> <td>   -0.033</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_augmented</th>   <td>    0.0075</td> <td>    0.006</td> <td>    1.273</td> <td> 0.204</td> <td>   -0.004</td> <td>    0.019</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>150.661</td> <th>  Durbin-Watson:     </th> <td>   1.990</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 430.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.491</td>  <th>  Prob(JB):          </th> <td>2.97e-94</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.518</td>  <th>  Cond. No.          </th> <td>    4.14</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       female2male_rate   R-squared:                       0.218\n",
       "Model:                            OLS   Adj. R-squared:                  0.210\n",
       "Method:                 Least Squares   F-statistic:                     26.76\n",
       "Date:                Tue, 15 Mar 2022   Prob (F-statistic):           6.96e-24\n",
       "Time:                        21:09:14   Log-Likelihood:                 743.74\n",
       "No. Observations:                 486   AIC:                            -1475.\n",
       "Df Residuals:                     480   BIC:                            -1450.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "is_aws             0.0231      0.006      3.953      0.000       0.012       0.035\n",
       "is_baidu           0.0640      0.006     10.929      0.000       0.052       0.076\n",
       "is_aliyun          0.0771      0.006     13.165      0.000       0.066       0.089\n",
       "is_Pretrained      0.0186      0.005      3.896      0.000       0.009       0.028\n",
       "is_adversarial    -0.0214      0.006     -3.661      0.000      -0.033      -0.010\n",
       "is_augmented       0.0075      0.006      1.273      0.204      -0.004       0.019\n",
       "==============================================================================\n",
       "Omnibus:                      150.661   Durbin-Watson:                   1.990\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              430.709\n",
       "Skew:                           1.491   Prob(JB):                     2.97e-94\n",
       "Kurtosis:                       6.518   Cond. No.                         4.14\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_exp = ['is_google', 'is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC', 'is_34', 'is_50']\n",
    "\n",
    "# baseline setting: raw + UAP + 18\n",
    "exp_vs = ['is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented']\n",
    "\n",
    "dp_variable = 'female2male_rate'\n",
    "\n",
    "formula = '{} ~ 0+{}'.format(dp_variable, '+'.join(exp_vs)) # exclude the intercept\n",
    "# formula = Generate_Compare_Formula(formula, 'is_FGSM', 'is_DEEPFOOL')\n",
    "\n",
    "# add cross terms to formula\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_augmented',]])\n",
    "# formula += '+' + '+'.join([f'I({attr1}*{attr2})' for attr1 in ['is_Pretrained', 'is_adversarial', 'is_augmented', ] for attr2 in ['is_34', 'is_50']])\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC',]])\n",
    "\n",
    "print(formula)\n",
    "model = ols(formula, data=res_df)\n",
    "results = model.fit()\n",
    "# export_ols(results, './ols_result/imagenet/joint_ols_match.csv')\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression C\n",
    "\n",
    "dependent variable: female2male rate\n",
    "\n",
    "explain variables: platform + pretraining + dataset + adversarial algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female2male_rate ~ 0+is_aws+is_baidu+is_aliyun+is_Pretrained+is_adversarial+is_augmented+is_PGD+is_FGSM+is_BLB+is_CW2+is_DEEPFOOL+is_STEP_LLC+is_RFGSM+is_LLC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>female2male_rate</td> <th>  R-squared:         </th> <td>   0.558</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   45.82</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 18 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>3.79e-75</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:40:11</td>     <th>  Log-Likelihood:    </th> <td>  882.35</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   486</td>      <th>  AIC:               </th> <td>  -1737.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   472</td>      <th>  BIC:               </th> <td>  -1678.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aws</th>         <td>   -0.0075</td> <td>    0.007</td> <td>   -1.102</td> <td> 0.271</td> <td>   -0.021</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_baidu</th>       <td>    0.0334</td> <td>    0.007</td> <td>    4.921</td> <td> 0.000</td> <td>    0.020</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aliyun</th>      <td>    0.0465</td> <td>    0.007</td> <td>    6.851</td> <td> 0.000</td> <td>    0.033</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_Pretrained</th>  <td>    0.0186</td> <td>    0.004</td> <td>    5.138</td> <td> 0.000</td> <td>    0.012</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_adversarial</th> <td>   -0.0214</td> <td>    0.004</td> <td>   -4.829</td> <td> 0.000</td> <td>   -0.030</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_augmented</th>   <td>    0.0075</td> <td>    0.004</td> <td>    1.679</td> <td> 0.094</td> <td>   -0.001</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_PGD</th>         <td>    0.0559</td> <td>    0.008</td> <td>    7.272</td> <td> 0.000</td> <td>    0.041</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_FGSM</th>        <td>    0.0924</td> <td>    0.008</td> <td>   12.012</td> <td> 0.000</td> <td>    0.077</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_BLB</th>         <td>   -0.0002</td> <td>    0.008</td> <td>   -0.031</td> <td> 0.976</td> <td>   -0.015</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_CW2</th>         <td>    0.0011</td> <td>    0.008</td> <td>    0.140</td> <td> 0.889</td> <td>   -0.014</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_DEEPFOOL</th>    <td>   -0.0126</td> <td>    0.008</td> <td>   -1.636</td> <td> 0.103</td> <td>   -0.028</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_STEP_LLC</th>    <td>    0.0703</td> <td>    0.008</td> <td>    9.142</td> <td> 0.000</td> <td>    0.055</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_RFGSM</th>       <td>    0.0393</td> <td>    0.008</td> <td>    5.105</td> <td> 0.000</td> <td>    0.024</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_LLC</th>         <td>    0.0295</td> <td>    0.008</td> <td>    3.835</td> <td> 0.000</td> <td>    0.014</td> <td>    0.045</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>141.171</td> <th>  Durbin-Watson:     </th> <td>   1.941</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 496.892</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.305</td>  <th>  Prob(JB):          </th> <td>1.26e-108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.211</td>  <th>  Cond. No.          </th> <td>    10.5</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       female2male_rate   R-squared:                       0.558\n",
       "Model:                            OLS   Adj. R-squared:                  0.546\n",
       "Method:                 Least Squares   F-statistic:                     45.82\n",
       "Date:                Fri, 18 Mar 2022   Prob (F-statistic):           3.79e-75\n",
       "Time:                        14:40:11   Log-Likelihood:                 882.35\n",
       "No. Observations:                 486   AIC:                            -1737.\n",
       "Df Residuals:                     472   BIC:                            -1678.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "is_aws            -0.0075      0.007     -1.102      0.271      -0.021       0.006\n",
       "is_baidu           0.0334      0.007      4.921      0.000       0.020       0.047\n",
       "is_aliyun          0.0465      0.007      6.851      0.000       0.033       0.060\n",
       "is_Pretrained      0.0186      0.004      5.138      0.000       0.012       0.026\n",
       "is_adversarial    -0.0214      0.004     -4.829      0.000      -0.030      -0.013\n",
       "is_augmented       0.0075      0.004      1.679      0.094      -0.001       0.016\n",
       "is_PGD             0.0559      0.008      7.272      0.000       0.041       0.071\n",
       "is_FGSM            0.0924      0.008     12.012      0.000       0.077       0.107\n",
       "is_BLB            -0.0002      0.008     -0.031      0.976      -0.015       0.015\n",
       "is_CW2             0.0011      0.008      0.140      0.889      -0.014       0.016\n",
       "is_DEEPFOOL       -0.0126      0.008     -1.636      0.103      -0.028       0.003\n",
       "is_STEP_LLC        0.0703      0.008      9.142      0.000       0.055       0.085\n",
       "is_RFGSM           0.0393      0.008      5.105      0.000       0.024       0.054\n",
       "is_LLC             0.0295      0.008      3.835      0.000       0.014       0.045\n",
       "==============================================================================\n",
       "Omnibus:                      141.171   Durbin-Watson:                   1.941\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              496.892\n",
       "Skew:                           1.305   Prob(JB):                    1.26e-108\n",
       "Kurtosis:                       7.211   Cond. No.                         10.5\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_exp = ['is_google', 'is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC', 'is_34', 'is_50']\n",
    "\n",
    "# baseline setting: raw + UAP + 18\n",
    "exp_vs = ['is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC']\n",
    "\n",
    "dp_variable = 'female2male_rate'\n",
    "\n",
    "formula = '{} ~ 0+{}'.format(dp_variable, '+'.join(exp_vs)) # exclude the intercept\n",
    "# formula = Generate_Compare_Formula(formula, 'is_FGSM', 'is_DEEPFOOL')\n",
    "\n",
    "# add cross terms to formula\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_augmented',]])\n",
    "# formula += '+' + '+'.join([f'I({attr1}*{attr2})' for attr1 in ['is_Pretrained', 'is_adversarial', 'is_augmented', ] for attr2 in ['is_34', 'is_50']])\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC',]])\n",
    "\n",
    "print(formula)\n",
    "model = ols(formula, data=res_df)\n",
    "results = model.fit()\n",
    "# export_ols(results, './ols_result/imagenet/joint_ols_match.csv')\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<F test: F=array([[2.5760685]]), p=0.10915965516675383, df_denom=472, df_num=1>\n",
      "<F test: F=array([[3.15124947]]), p=0.07651320054607465, df_denom=472, df_num=1>\n",
      "<F test: F=array([[13.65693753]]), p=0.0002451536224109335, df_denom=472, df_num=1>\n",
      "<F test: F=array([[1.61265348]]), p=0.20474490001854248, df_denom=472, df_num=1>\n",
      "<F test: F=array([[4.69458725]]), p=0.03075739606531983, df_denom=472, df_num=1>\n",
      "<F test: F=array([[3.49634725]]), p=0.0621231732578, df_denom=472, df_num=1>\n",
      "<F test: F=array([[8.23722151]]), p=0.004288258131355551, df_denom=472, df_num=1>\n"
     ]
    }
   ],
   "source": [
    "# Test: DeepFool \\approx BLB \\approx UAP \n",
    "# Test: UAP \\approx CW2 < LLC \\approx RFGSM < PGD < Step-LLC < FGSM\n",
    "Test_Wald_R(results, [1,-1], ['is_DEEPFOOL', 'is_BLB'])\n",
    "Test_Wald_R(results, [1,-1], ['is_DEEPFOOL', 'is_CW2'])\n",
    "Test_Wald_R(results, [1,-1], ['is_CW2', 'is_LLC'])\n",
    "Test_Wald_R(results, [1,-1], ['is_LLC', 'is_RFGSM'])\n",
    "Test_Wald_R(results, [1,-1], ['is_RFGSM', 'is_PGD'])\n",
    "Test_Wald_R(results, [1,-1], ['is_PGD', 'is_STEP_LLC'])\n",
    "Test_Wald_R(results, [1,-1], ['is_STEP_LLC', 'is_FGSM'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression D\n",
    "\n",
    "dependent variable: female2male rate\n",
    "\n",
    "explain variables: platform + pretraining + dataset + adversarial algorithm + surrogate depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female2male_rate ~ 0+is_aws+is_baidu+is_aliyun+is_Pretrained+is_adversarial+is_augmented+is_PGD+is_FGSM+is_BLB+is_CW2+is_DEEPFOOL+is_STEP_LLC+is_RFGSM+is_LLC+is_34+is_50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>female2male_rate</td> <th>  R-squared:         </th> <td>   0.575</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.562</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   42.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>1.83e-77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:09:15</td>     <th>  Log-Likelihood:    </th> <td>  892.02</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   486</td>      <th>  AIC:               </th> <td>  -1752.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   470</td>      <th>  BIC:               </th> <td>  -1685.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aws</th>         <td>    0.0019</td> <td>    0.007</td> <td>    0.265</td> <td> 0.791</td> <td>   -0.012</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_baidu</th>       <td>    0.0427</td> <td>    0.007</td> <td>    6.001</td> <td> 0.000</td> <td>    0.029</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aliyun</th>      <td>    0.0558</td> <td>    0.007</td> <td>    7.839</td> <td> 0.000</td> <td>    0.042</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_Pretrained</th>  <td>    0.0186</td> <td>    0.004</td> <td>    5.231</td> <td> 0.000</td> <td>    0.012</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_adversarial</th> <td>   -0.0214</td> <td>    0.004</td> <td>   -4.916</td> <td> 0.000</td> <td>   -0.030</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_augmented</th>   <td>    0.0075</td> <td>    0.004</td> <td>    1.709</td> <td> 0.088</td> <td>   -0.001</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_PGD</th>         <td>    0.0559</td> <td>    0.008</td> <td>    7.402</td> <td> 0.000</td> <td>    0.041</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_FGSM</th>        <td>    0.0924</td> <td>    0.008</td> <td>   12.227</td> <td> 0.000</td> <td>    0.078</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_BLB</th>         <td>   -0.0002</td> <td>    0.008</td> <td>   -0.031</td> <td> 0.975</td> <td>   -0.015</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_CW2</th>         <td>    0.0011</td> <td>    0.008</td> <td>    0.142</td> <td> 0.887</td> <td>   -0.014</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_DEEPFOOL</th>    <td>   -0.0126</td> <td>    0.008</td> <td>   -1.665</td> <td> 0.097</td> <td>   -0.027</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_STEP_LLC</th>    <td>    0.0703</td> <td>    0.008</td> <td>    9.306</td> <td> 0.000</td> <td>    0.055</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_RFGSM</th>       <td>    0.0393</td> <td>    0.008</td> <td>    5.197</td> <td> 0.000</td> <td>    0.024</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_LLC</th>         <td>    0.0295</td> <td>    0.008</td> <td>    3.904</td> <td> 0.000</td> <td>    0.015</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_34</th>          <td>   -0.0090</td> <td>    0.004</td> <td>   -2.075</td> <td> 0.039</td> <td>   -0.018</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_50</th>          <td>   -0.0190</td> <td>    0.004</td> <td>   -4.367</td> <td> 0.000</td> <td>   -0.028</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>129.379</td> <th>  Durbin-Watson:     </th> <td>   2.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 393.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.245</td>  <th>  Prob(JB):          </th> <td>4.02e-86</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.636</td>  <th>  Cond. No.          </th> <td>    11.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       female2male_rate   R-squared:                       0.575\n",
       "Model:                            OLS   Adj. R-squared:                  0.562\n",
       "Method:                 Least Squares   F-statistic:                     42.42\n",
       "Date:                Tue, 15 Mar 2022   Prob (F-statistic):           1.83e-77\n",
       "Time:                        21:09:15   Log-Likelihood:                 892.02\n",
       "No. Observations:                 486   AIC:                            -1752.\n",
       "Df Residuals:                     470   BIC:                            -1685.\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "is_aws             0.0019      0.007      0.265      0.791      -0.012       0.016\n",
       "is_baidu           0.0427      0.007      6.001      0.000       0.029       0.057\n",
       "is_aliyun          0.0558      0.007      7.839      0.000       0.042       0.070\n",
       "is_Pretrained      0.0186      0.004      5.231      0.000       0.012       0.026\n",
       "is_adversarial    -0.0214      0.004     -4.916      0.000      -0.030      -0.013\n",
       "is_augmented       0.0075      0.004      1.709      0.088      -0.001       0.016\n",
       "is_PGD             0.0559      0.008      7.402      0.000       0.041       0.071\n",
       "is_FGSM            0.0924      0.008     12.227      0.000       0.078       0.107\n",
       "is_BLB            -0.0002      0.008     -0.031      0.975      -0.015       0.015\n",
       "is_CW2             0.0011      0.008      0.142      0.887      -0.014       0.016\n",
       "is_DEEPFOOL       -0.0126      0.008     -1.665      0.097      -0.027       0.002\n",
       "is_STEP_LLC        0.0703      0.008      9.306      0.000       0.055       0.085\n",
       "is_RFGSM           0.0393      0.008      5.197      0.000       0.024       0.054\n",
       "is_LLC             0.0295      0.008      3.904      0.000       0.015       0.044\n",
       "is_34             -0.0090      0.004     -2.075      0.039      -0.018      -0.000\n",
       "is_50             -0.0190      0.004     -4.367      0.000      -0.028      -0.010\n",
       "==============================================================================\n",
       "Omnibus:                      129.379   Durbin-Watson:                   2.029\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              393.260\n",
       "Skew:                           1.245   Prob(JB):                     4.02e-86\n",
       "Kurtosis:                       6.636   Cond. No.                         11.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_exp = ['is_google', 'is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC', 'is_34', 'is_50']\n",
    "\n",
    "# baseline setting: raw + UAP + 18\n",
    "exp_vs = ['is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC', 'is_34', 'is_50']\n",
    "\n",
    "dp_variable = 'female2male_rate'\n",
    "\n",
    "formula = '{} ~ 0+{}'.format(dp_variable, '+'.join(exp_vs)) # exclude the intercept\n",
    "# formula = Generate_Compare_Formula(formula, 'is_FGSM', 'is_DEEPFOOL')\n",
    "\n",
    "# add cross terms to formula\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_augmented',]])\n",
    "# formula += '+' + '+'.join([f'I({attr1}*{attr2})' for attr1 in ['is_Pretrained', 'is_adversarial', 'is_augmented', ] for attr2 in ['is_34', 'is_50']])\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC',]])\n",
    "\n",
    "print(formula)\n",
    "model = ols(formula, data=res_df)\n",
    "results = model.fit()\n",
    "# export_ols(results, './ols_result/imagenet/joint_ols_match.csv')\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression E\n",
    "\n",
    "dependent variable: female2male rate\n",
    "\n",
    "explain variables: platform + pretraining + dataset + adversarial algorithm + surrogate depth + cross terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female2male_rate ~ 0+is_aws+is_baidu+is_aliyun+is_Pretrained+is_adversarial+is_augmented+is_PGD+is_FGSM+is_BLB+is_CW2+is_DEEPFOOL+is_STEP_LLC+is_RFGSM+is_LLC+is_34+is_50+I(is_Pretrained*is_adversarial)+I(is_Pretrained*is_augmented)+I(is_Pretrained*is_34)+I(is_Pretrained*is_50)+I(is_adversarial*is_34)+I(is_adversarial*is_50)+I(is_augmented*is_34)+I(is_augmented*is_50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>female2male_rate</td> <th>  R-squared:         </th> <td>   0.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.580</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   30.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>3.66e-77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:09:15</td>     <th>  Log-Likelihood:    </th> <td>  906.78</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   486</td>      <th>  AIC:               </th> <td>  -1766.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   462</td>      <th>  BIC:               </th> <td>  -1665.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    23</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aws</th>                            <td>    0.0013</td> <td>    0.009</td> <td>    0.150</td> <td> 0.881</td> <td>   -0.015</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_baidu</th>                          <td>    0.0421</td> <td>    0.009</td> <td>    4.936</td> <td> 0.000</td> <td>    0.025</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aliyun</th>                         <td>    0.0552</td> <td>    0.009</td> <td>    6.470</td> <td> 0.000</td> <td>    0.038</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_Pretrained</th>                     <td>    0.0202</td> <td>    0.008</td> <td>    2.587</td> <td> 0.010</td> <td>    0.005</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_adversarial</th>                    <td>   -0.0325</td> <td>    0.009</td> <td>   -3.809</td> <td> 0.000</td> <td>   -0.049</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_augmented</th>                      <td>    0.0144</td> <td>    0.009</td> <td>    1.686</td> <td> 0.092</td> <td>   -0.002</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_PGD</th>                            <td>    0.0559</td> <td>    0.007</td> <td>    7.565</td> <td> 0.000</td> <td>    0.041</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_FGSM</th>                           <td>    0.0924</td> <td>    0.007</td> <td>   12.496</td> <td> 0.000</td> <td>    0.078</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_BLB</th>                            <td>   -0.0002</td> <td>    0.007</td> <td>   -0.032</td> <td> 0.975</td> <td>   -0.015</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_CW2</th>                            <td>    0.0011</td> <td>    0.007</td> <td>    0.145</td> <td> 0.885</td> <td>   -0.013</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_DEEPFOOL</th>                       <td>   -0.0126</td> <td>    0.007</td> <td>   -1.702</td> <td> 0.089</td> <td>   -0.027</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_STEP_LLC</th>                       <td>    0.0703</td> <td>    0.007</td> <td>    9.511</td> <td> 0.000</td> <td>    0.056</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_RFGSM</th>                          <td>    0.0393</td> <td>    0.007</td> <td>    5.311</td> <td> 0.000</td> <td>    0.025</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_LLC</th>                            <td>    0.0295</td> <td>    0.007</td> <td>    3.990</td> <td> 0.000</td> <td>    0.015</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_34</th>                             <td>-4.619e-06</td> <td>    0.009</td> <td>   -0.001</td> <td> 1.000</td> <td>   -0.017</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_50</th>                             <td>   -0.0226</td> <td>    0.009</td> <td>   -2.644</td> <td> 0.008</td> <td>   -0.039</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Pretrained * is_adversarial)</th> <td>   -0.0024</td> <td>    0.009</td> <td>   -0.279</td> <td> 0.780</td> <td>   -0.019</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Pretrained * is_augmented)</th>   <td>    0.0097</td> <td>    0.009</td> <td>    1.142</td> <td> 0.254</td> <td>   -0.007</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Pretrained * is_34)</th>          <td>   -0.0026</td> <td>    0.009</td> <td>   -0.308</td> <td> 0.758</td> <td>   -0.019</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Pretrained * is_50)</th>          <td>   -0.0093</td> <td>    0.009</td> <td>   -1.091</td> <td> 0.276</td> <td>   -0.026</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_adversarial * is_34)</th>         <td>    0.0023</td> <td>    0.010</td> <td>    0.220</td> <td> 0.826</td> <td>   -0.018</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_adversarial * is_50)</th>         <td>    0.0345</td> <td>    0.010</td> <td>    3.299</td> <td> 0.001</td> <td>    0.014</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_augmented * is_34)</th>           <td>   -0.0255</td> <td>    0.010</td> <td>   -2.438</td> <td> 0.015</td> <td>   -0.046</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_augmented * is_50)</th>           <td>   -0.0100</td> <td>    0.010</td> <td>   -0.952</td> <td> 0.341</td> <td>   -0.030</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>92.114</td> <th>  Durbin-Watson:     </th> <td>   2.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 239.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.937</td> <th>  Prob(JB):          </th> <td>9.64e-53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.884</td> <th>  Cond. No.          </th> <td>    15.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       female2male_rate   R-squared:                       0.600\n",
       "Model:                            OLS   Adj. R-squared:                  0.580\n",
       "Method:                 Least Squares   F-statistic:                     30.16\n",
       "Date:                Tue, 15 Mar 2022   Prob (F-statistic):           3.66e-77\n",
       "Time:                        21:09:15   Log-Likelihood:                 906.78\n",
       "No. Observations:                 486   AIC:                            -1766.\n",
       "Df Residuals:                     462   BIC:                            -1665.\n",
       "Df Model:                          23                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================================\n",
       "                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------\n",
       "is_aws                                0.0013      0.009      0.150      0.881      -0.015       0.018\n",
       "is_baidu                              0.0421      0.009      4.936      0.000       0.025       0.059\n",
       "is_aliyun                             0.0552      0.009      6.470      0.000       0.038       0.072\n",
       "is_Pretrained                         0.0202      0.008      2.587      0.010       0.005       0.035\n",
       "is_adversarial                       -0.0325      0.009     -3.809      0.000      -0.049      -0.016\n",
       "is_augmented                          0.0144      0.009      1.686      0.092      -0.002       0.031\n",
       "is_PGD                                0.0559      0.007      7.565      0.000       0.041       0.070\n",
       "is_FGSM                               0.0924      0.007     12.496      0.000       0.078       0.107\n",
       "is_BLB                               -0.0002      0.007     -0.032      0.975      -0.015       0.014\n",
       "is_CW2                                0.0011      0.007      0.145      0.885      -0.013       0.016\n",
       "is_DEEPFOOL                          -0.0126      0.007     -1.702      0.089      -0.027       0.002\n",
       "is_STEP_LLC                           0.0703      0.007      9.511      0.000       0.056       0.085\n",
       "is_RFGSM                              0.0393      0.007      5.311      0.000       0.025       0.054\n",
       "is_LLC                                0.0295      0.007      3.990      0.000       0.015       0.044\n",
       "is_34                             -4.619e-06      0.009     -0.001      1.000      -0.017       0.017\n",
       "is_50                                -0.0226      0.009     -2.644      0.008      -0.039      -0.006\n",
       "I(is_Pretrained * is_adversarial)    -0.0024      0.009     -0.279      0.780      -0.019       0.014\n",
       "I(is_Pretrained * is_augmented)       0.0097      0.009      1.142      0.254      -0.007       0.027\n",
       "I(is_Pretrained * is_34)             -0.0026      0.009     -0.308      0.758      -0.019       0.014\n",
       "I(is_Pretrained * is_50)             -0.0093      0.009     -1.091      0.276      -0.026       0.007\n",
       "I(is_adversarial * is_34)             0.0023      0.010      0.220      0.826      -0.018       0.023\n",
       "I(is_adversarial * is_50)             0.0345      0.010      3.299      0.001       0.014       0.055\n",
       "I(is_augmented * is_34)              -0.0255      0.010     -2.438      0.015      -0.046      -0.005\n",
       "I(is_augmented * is_50)              -0.0100      0.010     -0.952      0.341      -0.030       0.011\n",
       "==============================================================================\n",
       "Omnibus:                       92.114   Durbin-Watson:                   2.154\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              239.543\n",
       "Skew:                           0.937   Prob(JB):                     9.64e-53\n",
       "Kurtosis:                       5.884   Cond. No.                         15.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_exp = ['is_google', 'is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC', 'is_34', 'is_50']\n",
    "\n",
    "# baseline setting: raw + UAP + 18\n",
    "exp_vs = ['is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC', 'is_34', 'is_50']\n",
    "\n",
    "dp_variable = 'female2male_rate'\n",
    "\n",
    "formula = '{} ~ 0+{}'.format(dp_variable, '+'.join(exp_vs)) # exclude the intercept\n",
    "# formula = Generate_Compare_Formula(formula, 'is_FGSM', 'is_DEEPFOOL')\n",
    "\n",
    "# add cross terms to formula\n",
    "formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_augmented',]])\n",
    "formula += '+' + '+'.join([f'I({attr1}*{attr2})' for attr1 in ['is_Pretrained', 'is_adversarial', 'is_augmented', ] for attr2 in ['is_34', 'is_50']])\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC',]])\n",
    "\n",
    "print(formula)\n",
    "model = ols(formula, data=res_df)\n",
    "results = model.fit()\n",
    "# export_ols(results, './ols_result/imagenet/joint_ols_match.csv')\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression F\n",
    "\n",
    "dependent variable: male2female rate\n",
    "\n",
    "explain variables: platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male2female_rate ~ 0+is_aws+is_baidu+is_aliyun\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>male2female_rate</td> <th>  R-squared:         </th> <td>   0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   131.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>2.80e-46</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:09:15</td>     <th>  Log-Likelihood:    </th> <td>  785.86</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   486</td>      <th>  AIC:               </th> <td>  -1566.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   483</td>      <th>  BIC:               </th> <td>  -1553.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aws</th>    <td>    0.0360</td> <td>    0.004</td> <td>    9.522</td> <td> 0.000</td> <td>    0.029</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_baidu</th>  <td>    0.1170</td> <td>    0.004</td> <td>   30.902</td> <td> 0.000</td> <td>    0.110</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aliyun</th> <td>    0.0494</td> <td>    0.004</td> <td>   13.054</td> <td> 0.000</td> <td>    0.042</td> <td>    0.057</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>228.999</td> <th>  Durbin-Watson:     </th> <td>   1.791</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1335.092</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.003</td>  <th>  Prob(JB):          </th> <td>1.23e-290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.063</td>  <th>  Cond. No.          </th> <td>    1.00</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       male2female_rate   R-squared:                       0.352\n",
       "Model:                            OLS   Adj. R-squared:                  0.350\n",
       "Method:                 Least Squares   F-statistic:                     131.4\n",
       "Date:                Tue, 15 Mar 2022   Prob (F-statistic):           2.80e-46\n",
       "Time:                        21:09:15   Log-Likelihood:                 785.86\n",
       "No. Observations:                 486   AIC:                            -1566.\n",
       "Df Residuals:                     483   BIC:                            -1553.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "is_aws         0.0360      0.004      9.522      0.000       0.029       0.043\n",
       "is_baidu       0.1170      0.004     30.902      0.000       0.110       0.124\n",
       "is_aliyun      0.0494      0.004     13.054      0.000       0.042       0.057\n",
       "==============================================================================\n",
       "Omnibus:                      228.999   Durbin-Watson:                   1.791\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1335.092\n",
       "Skew:                           2.003   Prob(JB):                    1.23e-290\n",
       "Kurtosis:                      10.063   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_exp = ['is_google', 'is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC', 'is_34', 'is_50']\n",
    "\n",
    "# baseline setting: raw + UAP + 18\n",
    "exp_vs = ['is_aws', 'is_baidu', 'is_aliyun']\n",
    "\n",
    "dp_variable = 'male2female_rate'\n",
    "\n",
    "formula = '{} ~ 0+{}'.format(dp_variable, '+'.join(exp_vs)) # exclude the intercept\n",
    "# formula = Generate_Compare_Formula(formula, 'is_FGSM', 'is_DEEPFOOL')\n",
    "\n",
    "# add cross terms to formula\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_augmented',]])\n",
    "# formula += '+' + '+'.join([f'I({attr1}*{attr2})' for attr1 in ['is_Pretrained', 'is_adversarial', 'is_augmented', ] for attr2 in ['is_34', 'is_50']])\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC',]])\n",
    "\n",
    "print(formula)\n",
    "model = ols(formula, data=res_df)\n",
    "results = model.fit()\n",
    "# export_ols(results, './ols_result/imagenet/joint_ols_match.csv')\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<F test: F=array([[6.23571693]]), p=0.012851749107181603, df_denom=483, df_num=1>\n",
      "<F test: F=array([[159.28355094]]), p=9.26947776872456e-32, df_denom=483, df_num=1>\n"
     ]
    }
   ],
   "source": [
    "# Test: AWS < Aliyun < Baidu\n",
    "Test_Wald_R(results, [1,-1], ['is_aws', 'is_aliyun'])\n",
    "Test_Wald_R(results, [1,-1], ['is_aliyun', 'is_baidu'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression G\n",
    "\n",
    "dependent variable: male2female rate\n",
    "\n",
    "explain variables: platform + pretraining + dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male2female_rate ~ 0+is_aws+is_baidu+is_aliyun+is_Pretrained+is_adversarial+is_augmented\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>male2female_rate</td> <th>  R-squared:         </th> <td>   0.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   62.65</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>3.06e-50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:09:15</td>     <th>  Log-Likelihood:    </th> <td>  802.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   486</td>      <th>  AIC:               </th> <td>  -1593.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   480</td>      <th>  BIC:               </th> <td>  -1568.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aws</th>         <td>    0.0314</td> <td>    0.005</td> <td>    6.049</td> <td> 0.000</td> <td>    0.021</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_baidu</th>       <td>    0.1123</td> <td>    0.005</td> <td>   21.641</td> <td> 0.000</td> <td>    0.102</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aliyun</th>      <td>    0.0448</td> <td>    0.005</td> <td>    8.624</td> <td> 0.000</td> <td>    0.035</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_Pretrained</th>  <td>    0.0132</td> <td>    0.004</td> <td>    3.107</td> <td> 0.002</td> <td>    0.005</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_adversarial</th> <td>   -0.0155</td> <td>    0.005</td> <td>   -2.994</td> <td> 0.003</td> <td>   -0.026</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_augmented</th>   <td>    0.0097</td> <td>    0.005</td> <td>    1.877</td> <td> 0.061</td> <td>   -0.000</td> <td>    0.020</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>199.528</td> <th>  Durbin-Watson:     </th> <td>   1.931</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1019.795</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.745</td>  <th>  Prob(JB):          </th> <td>3.58e-222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.179</td>  <th>  Cond. No.          </th> <td>    4.14</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       male2female_rate   R-squared:                       0.395\n",
       "Model:                            OLS   Adj. R-squared:                  0.389\n",
       "Method:                 Least Squares   F-statistic:                     62.65\n",
       "Date:                Tue, 15 Mar 2022   Prob (F-statistic):           3.06e-50\n",
       "Time:                        21:09:15   Log-Likelihood:                 802.40\n",
       "No. Observations:                 486   AIC:                            -1593.\n",
       "Df Residuals:                     480   BIC:                            -1568.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "is_aws             0.0314      0.005      6.049      0.000       0.021       0.042\n",
       "is_baidu           0.1123      0.005     21.641      0.000       0.102       0.123\n",
       "is_aliyun          0.0448      0.005      8.624      0.000       0.035       0.055\n",
       "is_Pretrained      0.0132      0.004      3.107      0.002       0.005       0.021\n",
       "is_adversarial    -0.0155      0.005     -2.994      0.003      -0.026      -0.005\n",
       "is_augmented       0.0097      0.005      1.877      0.061      -0.000       0.020\n",
       "==============================================================================\n",
       "Omnibus:                      199.528   Durbin-Watson:                   1.931\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1019.795\n",
       "Skew:                           1.745   Prob(JB):                    3.58e-222\n",
       "Kurtosis:                       9.179   Cond. No.                         4.14\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_exp = ['is_google', 'is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC', 'is_34', 'is_50']\n",
    "\n",
    "# baseline setting: raw + UAP + 18\n",
    "exp_vs = ['is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented']\n",
    "\n",
    "dp_variable = 'male2female_rate'\n",
    "\n",
    "formula = '{} ~ 0+{}'.format(dp_variable, '+'.join(exp_vs)) # exclude the intercept\n",
    "# formula = Generate_Compare_Formula(formula, 'is_FGSM', 'is_DEEPFOOL')\n",
    "\n",
    "# add cross terms to formula\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_augmented',]])\n",
    "# formula += '+' + '+'.join([f'I({attr1}*{attr2})' for attr1 in ['is_Pretrained', 'is_adversarial', 'is_augmented', ] for attr2 in ['is_34', 'is_50']])\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC',]])\n",
    "\n",
    "print(formula)\n",
    "model = ols(formula, data=res_df)\n",
    "results = model.fit()\n",
    "# export_ols(results, './ols_result/imagenet/joint_ols_match.csv')\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression H\n",
    "\n",
    "dependent variable: male2female rate\n",
    "\n",
    "explain variables: platform + pretraining + dataset + adversarial algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male2female_rate ~ 0+is_aws+is_baidu+is_aliyun+is_Pretrained+is_adversarial+is_augmented+is_PGD+is_FGSM+is_BLB+is_CW2+is_DEEPFOOL+is_STEP_LLC+is_RFGSM+is_LLC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>male2female_rate</td> <th>  R-squared:         </th> <td>   0.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   41.09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 17 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>3.44e-69</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:48:35</td>     <th>  Log-Likelihood:    </th> <td>  864.26</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   486</td>      <th>  AIC:               </th> <td>  -1701.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   472</td>      <th>  BIC:               </th> <td>  -1642.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aws</th>         <td>    0.0024</td> <td>    0.007</td> <td>    0.337</td> <td> 0.737</td> <td>   -0.011</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_baidu</th>       <td>    0.0833</td> <td>    0.007</td> <td>   11.833</td> <td> 0.000</td> <td>    0.069</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aliyun</th>      <td>    0.0157</td> <td>    0.007</td> <td>    2.236</td> <td> 0.026</td> <td>    0.002</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_Pretrained</th>  <td>    0.0132</td> <td>    0.004</td> <td>    3.499</td> <td> 0.001</td> <td>    0.006</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_adversarial</th> <td>   -0.0155</td> <td>    0.005</td> <td>   -3.373</td> <td> 0.001</td> <td>   -0.025</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_augmented</th>   <td>    0.0097</td> <td>    0.005</td> <td>    2.114</td> <td> 0.035</td> <td>    0.001</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_PGD</th>         <td>    0.0474</td> <td>    0.008</td> <td>    5.932</td> <td> 0.000</td> <td>    0.032</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_FGSM</th>        <td>    0.0703</td> <td>    0.008</td> <td>    8.801</td> <td> 0.000</td> <td>    0.055</td> <td>    0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_BLB</th>         <td>    0.0150</td> <td>    0.008</td> <td>    1.885</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_CW2</th>         <td>    0.0135</td> <td>    0.008</td> <td>    1.690</td> <td> 0.092</td> <td>   -0.002</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_DEEPFOOL</th>    <td>    0.0078</td> <td>    0.008</td> <td>    0.973</td> <td> 0.331</td> <td>   -0.008</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_STEP_LLC</th>    <td>    0.0517</td> <td>    0.008</td> <td>    6.482</td> <td> 0.000</td> <td>    0.036</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_RFGSM</th>       <td>    0.0339</td> <td>    0.008</td> <td>    4.245</td> <td> 0.000</td> <td>    0.018</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_LLC</th>         <td>    0.0217</td> <td>    0.008</td> <td>    2.719</td> <td> 0.007</td> <td>    0.006</td> <td>    0.037</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>170.986</td> <th>  Durbin-Watson:     </th> <td>   1.801</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1044.053</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.392</td>  <th>  Prob(JB):          </th> <td>1.94e-227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.618</td>  <th>  Cond. No.          </th> <td>    10.5</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       male2female_rate   R-squared:                       0.531\n",
       "Model:                            OLS   Adj. R-squared:                  0.518\n",
       "Method:                 Least Squares   F-statistic:                     41.09\n",
       "Date:                Thu, 17 Mar 2022   Prob (F-statistic):           3.44e-69\n",
       "Time:                        23:48:35   Log-Likelihood:                 864.26\n",
       "No. Observations:                 486   AIC:                            -1701.\n",
       "Df Residuals:                     472   BIC:                            -1642.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "is_aws             0.0024      0.007      0.337      0.737      -0.011       0.016\n",
       "is_baidu           0.0833      0.007     11.833      0.000       0.069       0.097\n",
       "is_aliyun          0.0157      0.007      2.236      0.026       0.002       0.030\n",
       "is_Pretrained      0.0132      0.004      3.499      0.001       0.006       0.021\n",
       "is_adversarial    -0.0155      0.005     -3.373      0.001      -0.025      -0.006\n",
       "is_augmented       0.0097      0.005      2.114      0.035       0.001       0.019\n",
       "is_PGD             0.0474      0.008      5.932      0.000       0.032       0.063\n",
       "is_FGSM            0.0703      0.008      8.801      0.000       0.055       0.086\n",
       "is_BLB             0.0150      0.008      1.885      0.060      -0.001       0.031\n",
       "is_CW2             0.0135      0.008      1.690      0.092      -0.002       0.029\n",
       "is_DEEPFOOL        0.0078      0.008      0.973      0.331      -0.008       0.023\n",
       "is_STEP_LLC        0.0517      0.008      6.482      0.000       0.036       0.067\n",
       "is_RFGSM           0.0339      0.008      4.245      0.000       0.018       0.050\n",
       "is_LLC             0.0217      0.008      2.719      0.007       0.006       0.037\n",
       "==============================================================================\n",
       "Omnibus:                      170.986   Durbin-Watson:                   1.801\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1044.053\n",
       "Skew:                           1.392   Prob(JB):                    1.94e-227\n",
       "Kurtosis:                       9.618   Cond. No.                         10.5\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_exp = ['is_google', 'is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC', 'is_34', 'is_50']\n",
    "\n",
    "# baseline setting: raw + UAP + 18\n",
    "exp_vs = ['is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC']\n",
    "\n",
    "dp_variable = 'male2female_rate'\n",
    "\n",
    "formula = '{} ~ 0+{}'.format(dp_variable, '+'.join(exp_vs)) # exclude the intercept\n",
    "# formula = Generate_Compare_Formula(formula, 'is_FGSM', 'is_DEEPFOOL')\n",
    "\n",
    "# add cross terms to formula\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_augmented',]])\n",
    "# formula += '+' + '+'.join([f'I({attr1}*{attr2})' for attr1 in ['is_Pretrained', 'is_adversarial', 'is_augmented', ] for attr2 in ['is_34', 'is_50']])\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC',]])\n",
    "\n",
    "print(formula)\n",
    "model = ols(formula, data=res_df)\n",
    "results = model.fit()\n",
    "# export_ols(results, './ols_result/imagenet/joint_ols_match.csv')\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<F test: F=array([[0.83224926]]), p=0.36208864511881644, df_denom=472, df_num=1>\n",
      "<F test: F=array([[1.05753331]]), p=0.3043051466430184, df_denom=472, df_num=1>\n",
      "<F test: F=array([[2.32920702]]), p=0.12763632122587937, df_denom=472, df_num=1>\n",
      "<F test: F=array([[2.84814356]]), p=0.09214014046454463, df_denom=472, df_num=1>\n",
      "<F test: F=array([[0.30148915]]), p=0.5832100174634746, df_denom=472, df_num=1>\n",
      "<F test: F=array([[5.38184997]]), p=0.020772985887154354, df_denom=472, df_num=1>\n"
     ]
    }
   ],
   "source": [
    "# Result: UAP \\approx DeepFool; CW2 \\approx BLB \\approx LLC; RFGSM < PGD \\approx Step-LLC < FGSM\n",
    "Test_Wald_R(results, [1,-1], ['is_DEEPFOOL', 'is_BLB'])\n",
    "Test_Wald_R(results, [1,-1], ['is_CW2', 'is_LLC'])\n",
    "Test_Wald_R(results, [1,-1], ['is_LLC', 'is_RFGSM'])\n",
    "Test_Wald_R(results, [1,-1], ['is_RFGSM', 'is_PGD'])\n",
    "Test_Wald_R(results, [1,-1], ['is_PGD', 'is_STEP_LLC'])\n",
    "Test_Wald_R(results, [1,-1], ['is_STEP_LLC', 'is_FGSM'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression I\n",
    "\n",
    "dependent variable: male2female rate\n",
    "\n",
    "explain variables: platform + pretraining + dataset + adversarial algorithm + surrogate depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male2female_rate ~ 0+is_aws+is_baidu+is_aliyun+is_Pretrained+is_adversarial+is_augmented+is_PGD+is_FGSM+is_BLB+is_CW2+is_DEEPFOOL+is_STEP_LLC+is_RFGSM+is_LLC+is_34+is_50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>male2female_rate</td> <th>  R-squared:         </th> <td>   0.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.535</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   38.24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>1.25e-71</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:09:15</td>     <th>  Log-Likelihood:    </th> <td>  874.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   486</td>      <th>  AIC:               </th> <td>  -1716.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   470</td>      <th>  BIC:               </th> <td>  -1649.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aws</th>         <td>    0.0115</td> <td>    0.007</td> <td>    1.555</td> <td> 0.121</td> <td>   -0.003</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_baidu</th>       <td>    0.0924</td> <td>    0.007</td> <td>   12.507</td> <td> 0.000</td> <td>    0.078</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aliyun</th>      <td>    0.0249</td> <td>    0.007</td> <td>    3.364</td> <td> 0.001</td> <td>    0.010</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_Pretrained</th>  <td>    0.0132</td> <td>    0.004</td> <td>    3.563</td> <td> 0.000</td> <td>    0.006</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_adversarial</th> <td>   -0.0155</td> <td>    0.005</td> <td>   -3.435</td> <td> 0.001</td> <td>   -0.024</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_augmented</th>   <td>    0.0097</td> <td>    0.005</td> <td>    2.153</td> <td> 0.032</td> <td>    0.001</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_PGD</th>         <td>    0.0474</td> <td>    0.008</td> <td>    6.042</td> <td> 0.000</td> <td>    0.032</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_FGSM</th>        <td>    0.0703</td> <td>    0.008</td> <td>    8.963</td> <td> 0.000</td> <td>    0.055</td> <td>    0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_BLB</th>         <td>    0.0150</td> <td>    0.008</td> <td>    1.920</td> <td> 0.055</td> <td>   -0.000</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_CW2</th>         <td>    0.0135</td> <td>    0.008</td> <td>    1.721</td> <td> 0.086</td> <td>   -0.002</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_DEEPFOOL</th>    <td>    0.0078</td> <td>    0.008</td> <td>    0.991</td> <td> 0.322</td> <td>   -0.008</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_STEP_LLC</th>    <td>    0.0517</td> <td>    0.008</td> <td>    6.601</td> <td> 0.000</td> <td>    0.036</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_RFGSM</th>       <td>    0.0339</td> <td>    0.008</td> <td>    4.323</td> <td> 0.000</td> <td>    0.018</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_LLC</th>         <td>    0.0217</td> <td>    0.008</td> <td>    2.769</td> <td> 0.006</td> <td>    0.006</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_34</th>          <td>   -0.0076</td> <td>    0.005</td> <td>   -1.671</td> <td> 0.095</td> <td>   -0.016</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_50</th>          <td>   -0.0198</td> <td>    0.005</td> <td>   -4.377</td> <td> 0.000</td> <td>   -0.029</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>170.638</td> <th>  Durbin-Watson:     </th> <td>   1.877</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 984.137</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.409</td>  <th>  Prob(JB):          </th> <td>1.98e-214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.376</td>  <th>  Cond. No.          </th> <td>    11.7</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       male2female_rate   R-squared:                       0.550\n",
       "Model:                            OLS   Adj. R-squared:                  0.535\n",
       "Method:                 Least Squares   F-statistic:                     38.24\n",
       "Date:                Tue, 15 Mar 2022   Prob (F-statistic):           1.25e-71\n",
       "Time:                        21:09:15   Log-Likelihood:                 874.15\n",
       "No. Observations:                 486   AIC:                            -1716.\n",
       "Df Residuals:                     470   BIC:                            -1649.\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "is_aws             0.0115      0.007      1.555      0.121      -0.003       0.026\n",
       "is_baidu           0.0924      0.007     12.507      0.000       0.078       0.107\n",
       "is_aliyun          0.0249      0.007      3.364      0.001       0.010       0.039\n",
       "is_Pretrained      0.0132      0.004      3.563      0.000       0.006       0.020\n",
       "is_adversarial    -0.0155      0.005     -3.435      0.001      -0.024      -0.007\n",
       "is_augmented       0.0097      0.005      2.153      0.032       0.001       0.019\n",
       "is_PGD             0.0474      0.008      6.042      0.000       0.032       0.063\n",
       "is_FGSM            0.0703      0.008      8.963      0.000       0.055       0.086\n",
       "is_BLB             0.0150      0.008      1.920      0.055      -0.000       0.030\n",
       "is_CW2             0.0135      0.008      1.721      0.086      -0.002       0.029\n",
       "is_DEEPFOOL        0.0078      0.008      0.991      0.322      -0.008       0.023\n",
       "is_STEP_LLC        0.0517      0.008      6.601      0.000       0.036       0.067\n",
       "is_RFGSM           0.0339      0.008      4.323      0.000       0.018       0.049\n",
       "is_LLC             0.0217      0.008      2.769      0.006       0.006       0.037\n",
       "is_34             -0.0076      0.005     -1.671      0.095      -0.016       0.001\n",
       "is_50             -0.0198      0.005     -4.377      0.000      -0.029      -0.011\n",
       "==============================================================================\n",
       "Omnibus:                      170.638   Durbin-Watson:                   1.877\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              984.137\n",
       "Skew:                           1.409   Prob(JB):                    1.98e-214\n",
       "Kurtosis:                       9.376   Cond. No.                         11.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_exp = ['is_google', 'is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC', 'is_34', 'is_50']\n",
    "\n",
    "# baseline setting: raw + UAP + 18\n",
    "exp_vs = ['is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC', 'is_34', 'is_50']\n",
    "\n",
    "dp_variable = 'male2female_rate'\n",
    "\n",
    "formula = '{} ~ 0+{}'.format(dp_variable, '+'.join(exp_vs)) # exclude the intercept\n",
    "# formula = Generate_Compare_Formula(formula, 'is_FGSM', 'is_DEEPFOOL')\n",
    "\n",
    "# add cross terms to formula\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_augmented',]])\n",
    "# formula += '+' + '+'.join([f'I({attr1}*{attr2})' for attr1 in ['is_Pretrained', 'is_adversarial', 'is_augmented', ] for attr2 in ['is_34', 'is_50']])\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC',]])\n",
    "\n",
    "print(formula)\n",
    "model = ols(formula, data=res_df)\n",
    "results = model.fit()\n",
    "# export_ols(results, './ols_result/imagenet/joint_ols_match.csv')\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression J\n",
    "\n",
    "dependent variable: male2female rate\n",
    "\n",
    "explain variables: platform + pretraining + dataset + adversarial algorithm + surrogate depth + cross terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male2female_rate ~ 0+is_aws+is_baidu+is_aliyun+is_Pretrained+is_adversarial+is_augmented+is_PGD+is_FGSM+is_BLB+is_CW2+is_DEEPFOOL+is_STEP_LLC+is_RFGSM+is_LLC+is_34+is_50+I(is_Pretrained*is_adversarial)+I(is_Pretrained*is_augmented)+I(is_Pretrained*is_34)+I(is_Pretrained*is_50)+I(is_adversarial*is_34)+I(is_adversarial*is_50)+I(is_augmented*is_34)+I(is_augmented*is_50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>male2female_rate</td> <th>  R-squared:         </th> <td>   0.575</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   27.20</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>2.81e-71</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:09:15</td>     <th>  Log-Likelihood:    </th> <td>  888.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   486</td>      <th>  AIC:               </th> <td>  -1729.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   462</td>      <th>  BIC:               </th> <td>  -1628.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    23</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aws</th>                            <td>    0.0055</td> <td>    0.009</td> <td>    0.615</td> <td> 0.539</td> <td>   -0.012</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_baidu</th>                          <td>    0.0864</td> <td>    0.009</td> <td>    9.744</td> <td> 0.000</td> <td>    0.069</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aliyun</th>                         <td>    0.0188</td> <td>    0.009</td> <td>    2.123</td> <td> 0.034</td> <td>    0.001</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_Pretrained</th>                     <td>    0.0158</td> <td>    0.008</td> <td>    1.954</td> <td> 0.051</td> <td> -8.9e-05</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_adversarial</th>                    <td>   -0.0188</td> <td>    0.009</td> <td>   -2.126</td> <td> 0.034</td> <td>   -0.036</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_augmented</th>                      <td>    0.0110</td> <td>    0.009</td> <td>    1.244</td> <td> 0.214</td> <td>   -0.006</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_PGD</th>                            <td>    0.0474</td> <td>    0.008</td> <td>    6.168</td> <td> 0.000</td> <td>    0.032</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_FGSM</th>                           <td>    0.0703</td> <td>    0.008</td> <td>    9.151</td> <td> 0.000</td> <td>    0.055</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_BLB</th>                            <td>    0.0150</td> <td>    0.008</td> <td>    1.960</td> <td> 0.051</td> <td>-3.81e-05</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_CW2</th>                            <td>    0.0135</td> <td>    0.008</td> <td>    1.757</td> <td> 0.080</td> <td>   -0.002</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_DEEPFOOL</th>                       <td>    0.0078</td> <td>    0.008</td> <td>    1.012</td> <td> 0.312</td> <td>   -0.007</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_STEP_LLC</th>                       <td>    0.0517</td> <td>    0.008</td> <td>    6.739</td> <td> 0.000</td> <td>    0.037</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_RFGSM</th>                          <td>    0.0339</td> <td>    0.008</td> <td>    4.413</td> <td> 0.000</td> <td>    0.019</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_LLC</th>                            <td>    0.0217</td> <td>    0.008</td> <td>    2.826</td> <td> 0.005</td> <td>    0.007</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_34</th>                             <td>    0.0081</td> <td>    0.009</td> <td>    0.915</td> <td> 0.361</td> <td>   -0.009</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_50</th>                             <td>   -0.0012</td> <td>    0.009</td> <td>   -0.137</td> <td> 0.891</td> <td>   -0.019</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Pretrained * is_adversarial)</th> <td>    0.0054</td> <td>    0.009</td> <td>    0.608</td> <td> 0.544</td> <td>   -0.012</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Pretrained * is_augmented)</th>   <td>    0.0269</td> <td>    0.009</td> <td>    3.037</td> <td> 0.003</td> <td>    0.010</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Pretrained * is_34)</th>          <td>   -0.0139</td> <td>    0.009</td> <td>   -1.564</td> <td> 0.118</td> <td>   -0.031</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Pretrained * is_50)</th>          <td>   -0.0264</td> <td>    0.009</td> <td>   -2.977</td> <td> 0.003</td> <td>   -0.044</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_adversarial * is_34)</th>         <td>   -0.0038</td> <td>    0.011</td> <td>   -0.353</td> <td> 0.724</td> <td>   -0.025</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_adversarial * is_50)</th>         <td>    0.0057</td> <td>    0.011</td> <td>    0.521</td> <td> 0.602</td> <td>   -0.016</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_augmented * is_34)</th>           <td>   -0.0224</td> <td>    0.011</td> <td>   -2.062</td> <td> 0.040</td> <td>   -0.044</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_augmented * is_50)</th>           <td>   -0.0219</td> <td>    0.011</td> <td>   -2.013</td> <td> 0.045</td> <td>   -0.043</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>147.602</td> <th>  Durbin-Watson:     </th> <td>   2.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 783.221</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.218</td>  <th>  Prob(JB):          </th> <td>8.43e-171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.722</td>  <th>  Cond. No.          </th> <td>    15.8</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       male2female_rate   R-squared:                       0.575\n",
       "Model:                            OLS   Adj. R-squared:                  0.554\n",
       "Method:                 Least Squares   F-statistic:                     27.20\n",
       "Date:                Tue, 15 Mar 2022   Prob (F-statistic):           2.81e-71\n",
       "Time:                        21:09:15   Log-Likelihood:                 888.38\n",
       "No. Observations:                 486   AIC:                            -1729.\n",
       "Df Residuals:                     462   BIC:                            -1628.\n",
       "Df Model:                          23                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================================\n",
       "                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------\n",
       "is_aws                                0.0055      0.009      0.615      0.539      -0.012       0.023\n",
       "is_baidu                              0.0864      0.009      9.744      0.000       0.069       0.104\n",
       "is_aliyun                             0.0188      0.009      2.123      0.034       0.001       0.036\n",
       "is_Pretrained                         0.0158      0.008      1.954      0.051    -8.9e-05       0.032\n",
       "is_adversarial                       -0.0188      0.009     -2.126      0.034      -0.036      -0.001\n",
       "is_augmented                          0.0110      0.009      1.244      0.214      -0.006       0.028\n",
       "is_PGD                                0.0474      0.008      6.168      0.000       0.032       0.062\n",
       "is_FGSM                               0.0703      0.008      9.151      0.000       0.055       0.085\n",
       "is_BLB                                0.0150      0.008      1.960      0.051   -3.81e-05       0.030\n",
       "is_CW2                                0.0135      0.008      1.757      0.080      -0.002       0.029\n",
       "is_DEEPFOOL                           0.0078      0.008      1.012      0.312      -0.007       0.023\n",
       "is_STEP_LLC                           0.0517      0.008      6.739      0.000       0.037       0.067\n",
       "is_RFGSM                              0.0339      0.008      4.413      0.000       0.019       0.049\n",
       "is_LLC                                0.0217      0.008      2.826      0.005       0.007       0.037\n",
       "is_34                                 0.0081      0.009      0.915      0.361      -0.009       0.026\n",
       "is_50                                -0.0012      0.009     -0.137      0.891      -0.019       0.016\n",
       "I(is_Pretrained * is_adversarial)     0.0054      0.009      0.608      0.544      -0.012       0.023\n",
       "I(is_Pretrained * is_augmented)       0.0269      0.009      3.037      0.003       0.010       0.044\n",
       "I(is_Pretrained * is_34)             -0.0139      0.009     -1.564      0.118      -0.031       0.004\n",
       "I(is_Pretrained * is_50)             -0.0264      0.009     -2.977      0.003      -0.044      -0.009\n",
       "I(is_adversarial * is_34)            -0.0038      0.011     -0.353      0.724      -0.025       0.018\n",
       "I(is_adversarial * is_50)             0.0057      0.011      0.521      0.602      -0.016       0.027\n",
       "I(is_augmented * is_34)              -0.0224      0.011     -2.062      0.040      -0.044      -0.001\n",
       "I(is_augmented * is_50)              -0.0219      0.011     -2.013      0.045      -0.043      -0.001\n",
       "==============================================================================\n",
       "Omnibus:                      147.602   Durbin-Watson:                   2.000\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.221\n",
       "Skew:                           1.218   Prob(JB):                    8.43e-171\n",
       "Kurtosis:                       8.722   Cond. No.                         15.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_exp = ['is_google', 'is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC', 'is_34', 'is_50']\n",
    "\n",
    "# baseline setting: raw + UAP + 18\n",
    "exp_vs = ['is_aws', 'is_baidu', 'is_aliyun', 'is_Pretrained', 'is_adversarial', 'is_augmented', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC', 'is_34', 'is_50']\n",
    "\n",
    "dp_variable = 'male2female_rate'\n",
    "\n",
    "formula = '{} ~ 0+{}'.format(dp_variable, '+'.join(exp_vs)) # exclude the intercept\n",
    "# formula = Generate_Compare_Formula(formula, 'is_FGSM', 'is_DEEPFOOL')\n",
    "\n",
    "# add cross terms to formula\n",
    "formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_augmented',]])\n",
    "formula += '+' + '+'.join([f'I({attr1}*{attr2})' for attr1 in ['is_Pretrained', 'is_adversarial', 'is_augmented', ] for attr2 in ['is_34', 'is_50']])\n",
    "# formula += '+' + '+'.join([f'I(is_Pretrained*{attr})' for attr in ['is_adversarial', 'is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC',]])\n",
    "\n",
    "print(formula)\n",
    "model = ols(formula, data=res_df)\n",
    "results = model.fit()\n",
    "# export_ols(results, './ols_result/imagenet/joint_ols_match.csv')\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>female2male_rate</th>\n",
       "      <th>male2female_rate</th>\n",
       "      <th>nr_female</th>\n",
       "      <th>nr_male</th>\n",
       "      <th>female2male_rate_100</th>\n",
       "      <th>male2female_rate_100</th>\n",
       "      <th>is_Pretrained</th>\n",
       "      <th>is_VGG_16</th>\n",
       "      <th>is_Inception_V3</th>\n",
       "      <th>is_ResNet_18</th>\n",
       "      <th>...</th>\n",
       "      <th>is_UAP</th>\n",
       "      <th>is_STEP_LLC</th>\n",
       "      <th>is_RFGSM</th>\n",
       "      <th>is_LLC</th>\n",
       "      <th>is_aws</th>\n",
       "      <th>is_aliyun</th>\n",
       "      <th>is_baidu</th>\n",
       "      <th>is_18</th>\n",
       "      <th>is_34</th>\n",
       "      <th>is_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>92</td>\n",
       "      <td>89</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.163043</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>92</td>\n",
       "      <td>94</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>46</td>\n",
       "      <td>51</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>88</td>\n",
       "      <td>83</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92</td>\n",
       "      <td>84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    female2male_rate  male2female_rate  nr_female  nr_male  \\\n",
       "0           0.060000          0.050000        100      100   \n",
       "1           0.050000          0.050000        100      100   \n",
       "2           0.032609          0.044944         92       89   \n",
       "3           0.163043          0.085106         92       94   \n",
       "4           0.086957          0.039216         46       51   \n",
       "..               ...               ...        ...      ...   \n",
       "76          0.018868          0.040000         53       50   \n",
       "77          0.100000          0.110000        100      100   \n",
       "78          0.030000          0.080000        100      100   \n",
       "79          0.113636          0.060241         88       83   \n",
       "80          0.000000          0.000000         92       84   \n",
       "\n",
       "    female2male_rate_100  male2female_rate_100  is_Pretrained  is_VGG_16  \\\n",
       "0                   0.06                  0.05              1          1   \n",
       "1                   0.05                  0.05              1          1   \n",
       "2                   0.03                  0.04              1          1   \n",
       "3                   0.15                  0.08              1          1   \n",
       "4                   0.04                  0.02              1          1   \n",
       "..                   ...                   ...            ...        ...   \n",
       "76                  0.01                  0.02              1          0   \n",
       "77                  0.10                  0.11              1          0   \n",
       "78                  0.03                  0.08              1          0   \n",
       "79                  0.10                  0.05              1          0   \n",
       "80                  0.00                  0.00              1          0   \n",
       "\n",
       "    is_Inception_V3  is_ResNet_18  ...  is_UAP  is_STEP_LLC  is_RFGSM  is_LLC  \\\n",
       "0                 0             0  ...       0            0         0       0   \n",
       "1                 0             0  ...       0            0         0       0   \n",
       "2                 0             0  ...       0            0         0       0   \n",
       "3                 0             0  ...       0            0         0       0   \n",
       "4                 0             0  ...       0            0         0       1   \n",
       "..              ...           ...  ...     ...          ...       ...     ...   \n",
       "76                0             1  ...       0            0         0       1   \n",
       "77                0             1  ...       0            0         0       0   \n",
       "78                0             1  ...       0            0         1       0   \n",
       "79                0             1  ...       0            1         0       0   \n",
       "80                0             1  ...       1            0         0       0   \n",
       "\n",
       "    is_aws  is_aliyun  is_baidu  is_18  is_34  is_50  \n",
       "0        0          1         0      0      0      0  \n",
       "1        0          1         0      0      0      0  \n",
       "2        0          1         0      0      0      0  \n",
       "3        0          1         0      0      0      0  \n",
       "4        0          1         0      0      0      0  \n",
       "..     ...        ...       ...    ...    ...    ...  \n",
       "76       1          0         0      1      0      0  \n",
       "77       1          0         0      1      0      0  \n",
       "78       1          0         0      1      0      0  \n",
       "79       1          0         0      1      0      0  \n",
       "80       1          0         0      1      0      0  \n",
       "\n",
       "[81 rows x 28 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_df = df[df['is_vgg']==1].copy(deep=True).reset_index(drop=True)\n",
    "inception_df = df[df['is_inception']==1].copy(deep=True).reset_index(drop=True)\n",
    "resnet_df = res_df[(res_df['is_Pretrained']==1) & (res_df['is_raw']==1) & (res_df['is_18']==1)].copy(deep=True).reset_index(drop=True)\n",
    "arch_df = pd.concat([vgg_df, inception_df, resnet_df], axis=0).reset_index(drop=True)\n",
    "arch_df = arch_df.rename(columns={'is_inception':'is_Inception_V3', 'is_vgg':'is_VGG_16', 'is_resnet':'is_ResNet_18'})\n",
    "arch_df.to_csv('gender_arch_df.csv')\n",
    "arch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female2male_rate ~ 0+is_aws+is_baidu+is_aliyun+I(is_VGG_16*is_PGD)+I(is_VGG_16*is_FGSM)+I(is_VGG_16*is_BLB)+I(is_VGG_16*is_CW2)+I(is_VGG_16*is_DEEPFOOL)+I(is_VGG_16*is_STEP_LLC)+I(is_VGG_16*is_RFGSM)+I(is_VGG_16*is_LLC)+I(is_Inception_V3*is_PGD)+I(is_Inception_V3*is_FGSM)+I(is_Inception_V3*is_BLB)+I(is_Inception_V3*is_CW2)+I(is_Inception_V3*is_DEEPFOOL)+I(is_Inception_V3*is_STEP_LLC)+I(is_Inception_V3*is_RFGSM)+I(is_Inception_V3*is_LLC)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>female2male_rate</td> <th>  R-squared:         </th> <td>   0.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Mar 2022</td> <th>  Prob (F-statistic):</th>  <td>0.00736</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:09:15</td>     <th>  Log-Likelihood:    </th> <td>  133.72</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    81</td>      <th>  AIC:               </th> <td>  -229.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    62</td>      <th>  BIC:               </th> <td>  -183.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    18</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aws</th>                           <td>    0.0368</td> <td>    0.012</td> <td>    2.955</td> <td> 0.004</td> <td>    0.012</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_baidu</th>                         <td>    0.0865</td> <td>    0.012</td> <td>    6.950</td> <td> 0.000</td> <td>    0.062</td> <td>    0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_aliyun</th>                        <td>    0.0931</td> <td>    0.012</td> <td>    7.479</td> <td> 0.000</td> <td>    0.068</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_VGG_16 * is_PGD)</th>            <td>   -0.0014</td> <td>    0.032</td> <td>   -0.044</td> <td> 0.965</td> <td>   -0.065</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_VGG_16 * is_FGSM)</th>           <td>    0.0673</td> <td>    0.032</td> <td>    2.102</td> <td> 0.040</td> <td>    0.003</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_VGG_16 * is_BLB)</th>            <td>   -0.0387</td> <td>    0.032</td> <td>   -1.209</td> <td> 0.231</td> <td>   -0.103</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_VGG_16 * is_CW2)</th>            <td>   -0.0420</td> <td>    0.032</td> <td>   -1.313</td> <td> 0.194</td> <td>   -0.106</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_VGG_16 * is_DEEPFOOL)</th>       <td>   -0.0575</td> <td>    0.032</td> <td>   -1.798</td> <td> 0.077</td> <td>   -0.122</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_VGG_16 * is_STEP_LLC)</th>       <td>    0.0585</td> <td>    0.032</td> <td>    1.827</td> <td> 0.072</td> <td>   -0.005</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_VGG_16 * is_RFGSM)</th>          <td>   -0.0054</td> <td>    0.032</td> <td>   -0.170</td> <td> 0.865</td> <td>   -0.069</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_VGG_16 * is_LLC)</th>            <td>   -0.0289</td> <td>    0.032</td> <td>   -0.904</td> <td> 0.369</td> <td>   -0.093</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Inception_V3 * is_PGD)</th>      <td>   -0.0151</td> <td>    0.032</td> <td>   -0.471</td> <td> 0.639</td> <td>   -0.079</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Inception_V3 * is_FGSM)</th>     <td>    0.0140</td> <td>    0.032</td> <td>    0.437</td> <td> 0.664</td> <td>   -0.050</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Inception_V3 * is_BLB)</th>      <td>   -0.0418</td> <td>    0.032</td> <td>   -1.306</td> <td> 0.196</td> <td>   -0.106</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Inception_V3 * is_CW2)</th>      <td>   -0.0421</td> <td>    0.032</td> <td>   -1.316</td> <td> 0.193</td> <td>   -0.106</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Inception_V3 * is_DEEPFOOL)</th> <td>   -0.0603</td> <td>    0.032</td> <td>   -1.883</td> <td> 0.064</td> <td>   -0.124</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Inception_V3 * is_STEP_LLC)</th> <td>   -0.0235</td> <td>    0.032</td> <td>   -0.734</td> <td> 0.465</td> <td>   -0.087</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Inception_V3 * is_RFGSM)</th>    <td>   -0.0048</td> <td>    0.032</td> <td>   -0.151</td> <td> 0.880</td> <td>   -0.069</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(is_Inception_V3 * is_LLC)</th>      <td>   -0.0341</td> <td>    0.032</td> <td>   -1.066</td> <td> 0.290</td> <td>   -0.098</td> <td>    0.030</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>28.327</td> <th>  Durbin-Watson:     </th> <td>   2.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  55.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.282</td> <th>  Prob(JB):          </th> <td>1.02e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.129</td> <th>  Cond. No.          </th> <td>    5.02</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       female2male_rate   R-squared:                       0.403\n",
       "Model:                            OLS   Adj. R-squared:                  0.230\n",
       "Method:                 Least Squares   F-statistic:                     2.327\n",
       "Date:                Tue, 15 Mar 2022   Prob (F-statistic):            0.00736\n",
       "Time:                        21:09:15   Log-Likelihood:                 133.72\n",
       "No. Observations:                  81   AIC:                            -229.4\n",
       "Df Residuals:                      62   BIC:                            -183.9\n",
       "Df Model:                          18                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================\n",
       "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------\n",
       "is_aws                               0.0368      0.012      2.955      0.004       0.012       0.062\n",
       "is_baidu                             0.0865      0.012      6.950      0.000       0.062       0.111\n",
       "is_aliyun                            0.0931      0.012      7.479      0.000       0.068       0.118\n",
       "I(is_VGG_16 * is_PGD)               -0.0014      0.032     -0.044      0.965      -0.065       0.063\n",
       "I(is_VGG_16 * is_FGSM)               0.0673      0.032      2.102      0.040       0.003       0.131\n",
       "I(is_VGG_16 * is_BLB)               -0.0387      0.032     -1.209      0.231      -0.103       0.025\n",
       "I(is_VGG_16 * is_CW2)               -0.0420      0.032     -1.313      0.194      -0.106       0.022\n",
       "I(is_VGG_16 * is_DEEPFOOL)          -0.0575      0.032     -1.798      0.077      -0.122       0.006\n",
       "I(is_VGG_16 * is_STEP_LLC)           0.0585      0.032      1.827      0.072      -0.005       0.122\n",
       "I(is_VGG_16 * is_RFGSM)             -0.0054      0.032     -0.170      0.865      -0.069       0.059\n",
       "I(is_VGG_16 * is_LLC)               -0.0289      0.032     -0.904      0.369      -0.093       0.035\n",
       "I(is_Inception_V3 * is_PGD)         -0.0151      0.032     -0.471      0.639      -0.079       0.049\n",
       "I(is_Inception_V3 * is_FGSM)         0.0140      0.032      0.437      0.664      -0.050       0.078\n",
       "I(is_Inception_V3 * is_BLB)         -0.0418      0.032     -1.306      0.196      -0.106       0.022\n",
       "I(is_Inception_V3 * is_CW2)         -0.0421      0.032     -1.316      0.193      -0.106       0.022\n",
       "I(is_Inception_V3 * is_DEEPFOOL)    -0.0603      0.032     -1.883      0.064      -0.124       0.004\n",
       "I(is_Inception_V3 * is_STEP_LLC)    -0.0235      0.032     -0.734      0.465      -0.087       0.040\n",
       "I(is_Inception_V3 * is_RFGSM)       -0.0048      0.032     -0.151      0.880      -0.069       0.059\n",
       "I(is_Inception_V3 * is_LLC)         -0.0341      0.032     -1.066      0.290      -0.098       0.030\n",
       "==============================================================================\n",
       "Omnibus:                       28.327   Durbin-Watson:                   2.008\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               55.226\n",
       "Skew:                           1.282   Prob(JB):                     1.02e-12\n",
       "Kurtosis:                       6.129   Cond. No.                         5.02\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regression w.r.t. architecture\n",
    "exp_vs = [ 'is_aws', 'is_baidu', 'is_aliyun', ]\n",
    "\n",
    "dp_variable = 'female2male_rate'\n",
    "formula = '{} ~ 0+{}'.format(dp_variable, '+'.join(exp_vs))\n",
    "\n",
    "# add cross terms to formula\n",
    "\n",
    "formula += '+' + '+'.join([f'I({model}*{attr})' for model in ['is_VGG_16', 'is_Inception_V3'] for attr in ['is_PGD', 'is_FGSM', 'is_BLB', 'is_CW2', 'is_DEEPFOOL', 'is_STEP_LLC', 'is_RFGSM', 'is_LLC',]])\n",
    "# formula += '+' + '+'.join([f'is_Pretrained*{attr}' for attr in ['is_adversarial', 'is_PGD', 'is_BLB', 'is_CW2', 'is_DEEPFOOL',  'is_RFGSM', ]])\n",
    "\n",
    "print(formula)\n",
    "model = ols(formula, data=arch_df)\n",
    "results = model.fit()\n",
    "export_ols(results, './ols_result/ols_arch.csv')\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for metric in ['female2male_rate', 'male2female_rate']:\n",
    "    architectures = ['VGG_16', 'ResNet_18', 'Inception_V3']\n",
    "    attacks = ['BLB', 'CW2', 'DEEPFOOL', 'LLC', 'STEP_LLC', 'PGD', 'FGSM', 'RFGSM', 'UAP']\n",
    "\n",
    "    arch_data = {'VGG_16':[], 'ResNet_18':[], 'Inception_V3':[]}\n",
    "    for arch in architectures:\n",
    "        for attack in attacks:\n",
    "            point = arch_df[(arch_df[f'is_{attack}']==1) & (arch_df[f'is_{arch}']==1)][metric].mean()\n",
    "            arch_data[arch].append(point)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    plt.xticks([i for i in range(len(attacks))], attacks, rotation=35, fontsize=10)\n",
    "    x = np.arange(len(attacks))\n",
    "    width = 0.2\n",
    "    ax.bar(x-1.5*width, arch_data['VGG_16'], width, label='VGG-16')\n",
    "    ax.bar(x-0.5*width,arch_data['ResNet_18'], width, label='ResNet-18')\n",
    "    ax.bar(x+0.5*width,arch_data['Inception_V3'],width,label='Inception V3')\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    # plt.savefig(f'{save_dir}/cross_architecture_{metric}.eps', format=\"eps\", bbox_inches = 'tight')\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a60ece403375a354abdea32cb66ab4bac61b3671feac0f32fdd4f2345c99bd8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('DS': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
